{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187210, 8)\n",
      "(1187210, 59)\n",
      "(1187198, 59)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('input_data.csv', index_col=0)\n",
    "print(df.shape)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Category', 'Installs','Content Rating'], drop_first=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.dropna(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759806, 58) (189952, 58) (237440, 58)\n",
      "(759806,) (189952,) (237440,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Rating'], axis=1).values\n",
    "y = df.Rating.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model RMSE : 0.6895426039410417\n"
     ]
    }
   ],
   "source": [
    "#최종모델과 성능을 비교할 기준모델\n",
    "y_pred = [y_train.mean()] * len(y_train)\n",
    "\n",
    "print(f'base model RMSE : {mean_squared_error(y_train, y_pred)**0.5}')\n",
    "#base model RMSE score: 0.6895426039410417"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 회귀모델 비교\n",
    "+ 학습 : train 데이터셋(1338134개) 사용\n",
    "+ 평가\n",
    "    + validation 데이터셋(334534개)으로 모델 성능 측정\n",
    "    + test 데이터셋(418168개)으로 best model의 성능 측정\n",
    "    + 지표는 RMSE, R2 score 사용\n",
    "        + RMSE : 0에 가까울수록 좋은 성능\n",
    "        + R2 score : 1에 가까울수록 좋은 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델별 cv 점수 저장할 list\n",
    "score_list = [['model', 'train_RMSE', 'train_R2', 'val_RMSE', 'val_R2', 'cv_score'],\n",
    "             ['LinearRegression'], \n",
    "             ['ElasticNet'], \n",
    "             ['Decision Tree'], \n",
    "             ['Random Forest'], \n",
    "             ['GBM'], \n",
    "             ['LGBM'], \n",
    "             ['XGB'],\n",
    "             ['Bagging']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression train RMSE : 0.6480135101947617\n",
      "LinearRegression train R2 : 0.11682673937793897\n",
      "\n",
      "LinearRegression val RMSE: 0.6480135101947617\n",
      "LinearRegression val R2: 0.1190980383561937\n",
      "\n",
      "LinearRegression cross validation RMSE: 0.6488470589866715\n"
     ]
    }
   ],
   "source": [
    "#LinearRegression\n",
    "lr = LinearRegression(n_jobs=8)\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"LinearRegression train RMSE : {rmse_train}\")\n",
    "print(f\"LinearRegression train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = lr.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"LinearRegression val RMSE: {rmse_test}\")\n",
    "print(f\"LinearRegression val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(lr, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"LinearRegression cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[1].append(rmse_train)\n",
    "score_list[1].append(r2_train)\n",
    "score_list[1].append(rmse_test)\n",
    "score_list[1].append(r2_test)\n",
    "score_list[1].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet train RMSE : 0.6895426039410417\n",
      "ElasticNet train R2 : 0.0\n",
      "\n",
      "ElasticNet val RMSE: 0.6895426039410417\n",
      "ElasticNet val R2: -9.849174564147134e-06\n",
      "\n",
      "ElasticNet cross validation RMSE: 0.6898189747445775\n"
     ]
    }
   ],
   "source": [
    "#ElasticNet\n",
    "elastic = ElasticNet(random_state=2)\n",
    "elastic.fit(X_train, y_train)\n",
    "y_train_pred = elastic.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"ElasticNet train RMSE : {rmse_train}\")\n",
    "print(f\"ElasticNet train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = elastic.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"ElasticNet val RMSE: {rmse_test}\")\n",
    "print(f\"ElasticNet val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(elastic, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"ElasticNet cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[2].append(rmse_train)\n",
    "score_list[2].append(r2_train)\n",
    "score_list[2].append(rmse_test)\n",
    "score_list[2].append(r2_test)\n",
    "score_list[2].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree train RMSE : 0.6632883260861491\n",
      "Decision Tree train R2 : 0.07470013592828761\n",
      "\n",
      "Decision Tree val RMSE: 0.6632883260861491\n",
      "Decision Tree val R2: 0.0756181161351841\n",
      "\n",
      "Decision Tree cross validation RMSE: 0.666572074796214\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "dt = DecisionTreeRegressor(max_depth = 8, max_features = 'sqrt')\n",
    "dt.fit(X_train, y_train)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Decision Tree train RMSE : {rmse_train}\")\n",
    "print(f\"Decision Tree train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = dt.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Decision Tree val RMSE: {rmse_test}\")\n",
    "print(f\"Decision Tree val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(dt, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"Decision Tree cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[3].append(rmse_train)\n",
    "score_list[3].append(r2_train)\n",
    "score_list[3].append(rmse_test)\n",
    "score_list[3].append(r2_test)\n",
    "score_list[3].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest train RMSE : 0.5690372232384866\n",
      "Random Forest train R2 : 0.31898113309930065\n",
      "\n",
      "Random Forest val RMSE: 0.5690372232384866\n",
      "Random Forest val R2: 0.16481227060532433\n",
      "\n",
      "Random Forest cross validation RMSE: 0.6307684282781312\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rf = RandomForestRegressor(max_depth = 20, n_estimators = 100)\n",
    "rf.fit(X_train,y_train)\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Random Forest train RMSE : {rmse_train}\")\n",
    "print(f\"Random Forest train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = rf.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Random Forest val RMSE: {rmse_test}\")\n",
    "print(f\"Random Forest val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(rf, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"Random Forest cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[4].append(rmse_train)\n",
    "score_list[4].append(r2_train)\n",
    "score_list[4].append(rmse_test)\n",
    "score_list[4].append(r2_test)\n",
    "score_list[4].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM train RMSE : 0.6293961231878967\n",
      "GBM train R2 : 0.16684478341118836\n",
      "\n",
      "GBM val RMSE: 0.6293961231878967\n",
      "GBM val R2: 0.16221125303647121\n",
      "\n",
      "GBM cross validation RMSE: 0.6328415487456673\n"
     ]
    }
   ],
   "source": [
    "#GBM\n",
    "gbm = GradientBoostingRegressor(learning_rate=0.1, max_depth=8, n_estimators=30, random_state=2)\n",
    "gbm.fit(X_train,y_train)\n",
    "y_train_pred = gbm.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"GBM train RMSE : {rmse_train}\")\n",
    "print(f\"GBM train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = gbm.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"GBM val RMSE: {rmse_test}\")\n",
    "print(f\"GBM val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(gbm, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"GBM cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[5].append(rmse_train)\n",
    "score_list[5].append(r2_train)\n",
    "score_list[5].append(rmse_test)\n",
    "score_list[5].append(r2_test)\n",
    "score_list[5].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM train RMSE : 0.6279584241448293\n",
      "LGBM train R2 : 0.17064670828835682\n",
      "\n",
      "LGBM val RMSE: 0.6279584241448293\n",
      "LGBM val R2: 0.17097708117025168\n",
      "\n",
      "LGBM cross validation RMSE: 0.6298078058056982\n"
     ]
    }
   ],
   "source": [
    "#lgbm \n",
    "lgbm = LGBMRegressor(random_state=2, n_jobs=8)\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_train_pred = lgbm.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"LGBM train RMSE : {rmse_train}\")\n",
    "print(f\"LGBM train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = lgbm.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"LGBM val RMSE: {rmse_test}\")\n",
    "print(f\"LGBM val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(lgbm, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"LGBM cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[6].append(rmse_train)\n",
    "score_list[6].append(r2_train)\n",
    "score_list[6].append(rmse_test)\n",
    "score_list[6].append(r2_test)\n",
    "score_list[6].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB train RMSE : 0.6215052573153973\n",
      "XGB train R2 : 0.18760469616736453\n",
      "\n",
      "XGB val RMSE: 0.6215052573153973\n",
      "XGB val R2: 0.1757911744168451\n",
      "\n",
      "XGB cross validation RMSE: 0.6275753145752293\n"
     ]
    }
   ],
   "source": [
    "#XGB \n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"XGB train RMSE : {rmse_train}\")\n",
    "print(f\"XGB train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = xgb.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"XGB val RMSE: {rmse_test}\")\n",
    "print(f\"XGB val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(xgb, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"XGB cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[7].append(rmse_train)\n",
    "score_list[7].append(r2_train)\n",
    "score_list[7].append(rmse_test)\n",
    "score_list[7].append(r2_test)\n",
    "score_list[7].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging train RMSE : 0.6215052573153973\n",
      "Bagging train R2 : 0.18760469616736453\n",
      "\n",
      "Bagging val RMSE: 0.6215052573153973\n",
      "Bagging val R2: 0.03604685660826956\n",
      "\n",
      "Bagging cross validation RMSE: 0.6785742238820952\n"
     ]
    }
   ],
   "source": [
    "#BaggingRegressor \n",
    "bagging = BaggingRegressor()\n",
    "bagging.fit(X_train, y_train)\n",
    "y_train_pred = xgb.predict(X_train)\n",
    "\n",
    "#train\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "rmse_train = mse_train ** 0.5\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Bagging train RMSE : {rmse_train}\")\n",
    "print(f\"Bagging train R2 : {r2_train}\\n\")\n",
    "\n",
    "#validation\n",
    "y_val_pred = bagging.predict(X_val)\n",
    "\n",
    "mse_test = mean_squared_error(y_val, y_val_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Bagging val RMSE: {rmse_test}\")\n",
    "print(f\"Bagging val R2: {r2_test}\\n\")\n",
    "\n",
    "# cv\n",
    "scores = cross_val_score(bagging, X, y, scoring='neg_mean_squared_error', cv=10, n_jobs=8)\n",
    "rmse_scores = (-scores) ** 0.5\n",
    "cv_score = rmse_scores.mean()\n",
    "\n",
    "print(f\"Bagging cross validation RMSE: {cv_score}\")\n",
    "\n",
    "score_list[8].append(rmse_train)\n",
    "score_list[8].append(r2_train)\n",
    "score_list[8].append(rmse_test)\n",
    "score_list[8].append(r2_test)\n",
    "score_list[8].append(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_RMSE</th>\n",
       "      <th>train_R2</th>\n",
       "      <th>val_RMSE</th>\n",
       "      <th>val_R2</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.648014</td>\n",
       "      <td>0.116827</td>\n",
       "      <td>0.648014</td>\n",
       "      <td>0.119098</td>\n",
       "      <td>0.648847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.689543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689543</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.689819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.663288</td>\n",
       "      <td>0.075618</td>\n",
       "      <td>0.666572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.569037</td>\n",
       "      <td>0.318981</td>\n",
       "      <td>0.569037</td>\n",
       "      <td>0.164812</td>\n",
       "      <td>0.630768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.629396</td>\n",
       "      <td>0.166845</td>\n",
       "      <td>0.629396</td>\n",
       "      <td>0.162211</td>\n",
       "      <td>0.632842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.627958</td>\n",
       "      <td>0.170647</td>\n",
       "      <td>0.627958</td>\n",
       "      <td>0.170977</td>\n",
       "      <td>0.629808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.187605</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.175791</td>\n",
       "      <td>0.627575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.187605</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.036047</td>\n",
       "      <td>0.678574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  train_RMSE  train_R2  val_RMSE    val_R2  cv_score\n",
       "0  LinearRegression    0.648014  0.116827  0.648014  0.119098  0.648847\n",
       "1        ElasticNet    0.689543  0.000000  0.689543 -0.000010  0.689819\n",
       "2     Decision Tree    0.663288  0.074700  0.663288  0.075618  0.666572\n",
       "3     Random Forest    0.569037  0.318981  0.569037  0.164812  0.630768\n",
       "4               GBM    0.629396  0.166845  0.629396  0.162211  0.632842\n",
       "5              LGBM    0.627958  0.170647  0.627958  0.170977  0.629808\n",
       "6               XGB    0.621505  0.187605  0.621505  0.175791  0.627575\n",
       "7           Bagging    0.621505  0.187605  0.621505  0.036047  0.678574"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_list[1:], columns=score_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "+ RandomForest, LGBM, XGB 세 모델의 성능이 유사하게 좋아보임\n",
    "+ 세 모델 모두 baseline model의 성능(0.6895426039410417)보다 좋은 결과\n",
    "+ 성능확인까지 걸린 시간이 각각 약 50분, 30초, 5분  \n",
    "    => 시간이 가장 적게 걸린 LGBM 모델 선택  \n",
    "    => RandomizedSearchCV를 이용해 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "[LightGBM] [Warning] Unknown parameter: normalize\n",
      "Best params : {'normalize': True, 'n_estimators': 50, 'max_depth': 30, 'learning_rate': 0.1}\n",
      "Best RMSE : 0.6313311130844016\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor(random_state=2, n_jobs=8)\n",
    "param_distribution = {\"n_estimators\": [15, 30, 50], \n",
    "                      \"max_depth\": [10, 30, 50], \n",
    "                      'learning_rate':[0.001, 0.005, 0.01, 0.1],\n",
    "                      'normalize':[True, False]}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_distribution, \n",
    "                                 scoring='neg_mean_squared_error', n_jobs=8, cv=10, verbose=1,\n",
    "                                 n_iter=2000, refit=True, random_state=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "print(\"Best params : {}\".format(random_search.best_params_))\n",
    "print(\"Best RMSE : {}\".format((-random_search.best_score_)**0.5))\n",
    "\n",
    "model = random_search.best_estimator_\n",
    "\n",
    "#Best params : {'n_estimators': 50, 'max_depth': 20, 'learning_rate': 0.1}\n",
    "#Best RMSE : 0.47677192300834276"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 모델 성능 평가\n",
    "+ test 데이터셋 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model test RMSE: 0.6215052573153973\n",
      "best model test R2: 0.15971898762037473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = mse_train ** 0.5\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"best model test RMSE: {rmse_test}\")\n",
    "print(f\"best model test R2: {r2_test}\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "702ecc25bf156e14d9df9ef3a5fdc4b988629ca0f5ee3f8cd11ceb825b3b8a58"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
